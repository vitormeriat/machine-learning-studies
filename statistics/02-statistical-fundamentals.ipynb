{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"width: 100%; background-color: #F7F7F7; margin-bottom: 3em;\">\n",
    "    <h1 style=\"font-family: courier; color: #AF4545; font-size: 4em; padding-top: .5em;\"><b>Statistical fundamentals and terminology for model building and validation</b></h1>\n",
    "    <img src=\"../img/statistics-head.png\">    \n",
    "</div>\n",
    "\n",
    "Este estudo é baseado no livro `Statistics for Machine Learning`, e o código abaixo possui trechos integrais do livro. Dito isso existem algumas adaptações, sugestões e complementos que jugo necessários.\n",
    "\n",
    "---\n",
    "\n",
    "Par iniciar vou importar os pacotes necessários na primeira parte do estudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta é uma introdução básica, a estatística é um tema para uma vida quanto mais um notebook. Com isso em mente, vou me ater aos principais pontos, os necessários para um bom conhecimento do universo do `Machine Learning`.\n",
    "\n",
    "> A análise preditiva se baseia na suposição de que a história tende a se repetir.\n",
    "\n",
    "Neste caso, para fazermos predições, nosso objetivo será ajustar um **modelo matemático** aos dados históricos validando suas principais medidas, de tal maneira que este modelo possa ser utilizado a fim de prever eventos futuros baseados nas mesmas **variáveis explicativas** que estudamos no passado.\n",
    "\n",
    "Modelos estatísticos são uma classe de modelos matemáticos que geralmente são especificados por equações matemáticas que relacionam uma ou mais variáveis a fim de se aproximar a realidade. Pressupostos incorporados por modelos estatísticos descrevem um conjunto de distribuições de probabilidade, que o diferencia dos modelos não estatísticos, matemáticos ou de aprendizado de máquina.\n",
    "\n",
    "Os modelos estatísticos sempre começam com algumas suposições subjacentes para as quais todas as variáveis devem se manter; então, o desempenho fornecido pelo modelo é estatisticamente significativo. Portanto, conhecer os vários bits envolvidos em todos os blocos de construção fornece uma base sólida para ser um bom cientista de dados.\n",
    "\n",
    "* População: é a totalidade, a lista completa de observações ou todos os pontos de dados sobre o assunto em estudo.\n",
    "* Amostra: uma amostra é um subconjunto de uma população, geralmente uma pequena parte da população que está sendo analisada.\n",
    "\n",
    "Geralmente, é caro realizar uma análise em uma população inteira; portanto, a maioria dos métodos estatísticos trata de tirar conclusões sobre uma população analisando uma amostra.\n",
    "\n",
    "* **Parâmetro versus estatística**: qualquer medida calculada na população é um parâmetro, enquanto que em uma amostra é chamada de estatística.\n",
    "* **Média**: Esta é uma média aritmética simples, calculada pela soma agregada dos valores dividida por uma contagem desses valores. A média é sensível aos valores discrepantes nos dados. Um valor externo é o valor de um conjunto ou coluna que é altamente desviado de muitos outros valores nos mesmos dados; geralmente tem valores muito altos ou baixos.\n",
    "* **Mediana**: é o ponto médio dos dados e é calculado organizando-os em ordem crescente ou decrescente. Se houver N observações.\n",
    "* **Moda**: é o ponto mais repetitivo nos dados:\n",
    "\n",
    "![0](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/d7ca0b32-24a6-43fd-8281-3f995895ff1b.png)\n",
    "\n",
    "O código abaixo usa o pacote stats e numpy para calular a média (median), mediana (median) e moda (mode).\n",
    "\n",
    "A matriz inicial foi criada utilizando o numpy, isso dado que os modelos estatísticos utilizados neste estudo serão criados utilizando o pacote scikit-learn, que é baseado no numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean : 4.33\n",
      "Median : 4.0\n",
      "Mode : 2\n"
     ]
    }
   ],
   "source": [
    "data = np.array([4,5,1,2,7,2,6,9,3])\n",
    "\n",
    "# Calculate Mean\n",
    "dt_mean = np.mean(data)\n",
    "print (\"Mean :\",round(dt_mean,2))\n",
    "              \n",
    "# Calculate Median                 \n",
    "dt_median = np.median(data)\n",
    "print (\"Median :\",dt_median)\n",
    "\n",
    "# Calculate Mode                     \n",
    "dt_mode =  stats.mode(data)\n",
    "print (\"Mode :\",dt_mode[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuições de probabilidade\n",
    "\n",
    "As principais distribuições de probabilidade estão implementadas na biblioteca `scipy.stats`. Todas as distribuições implementadas nesta biblioteca tem um conjunto rico de métodos os principais são:\n",
    "\n",
    "  - pdf: função densidade probabilidade ou função de probabilidade.\n",
    "  - cdf: função de distribuição acumulada.\n",
    "  - sf: função de sobreviência (complementar da cdf).\n",
    "  - ppf: função quantil (inversa da cdf).\n",
    "  - isf: inversa da função de sobreviência (complementar do inverso da cdf).\n",
    "  - stats: esperança, variância, assimetria (skew) e curtose.\n",
    "  - moment: Momentos não centrais.\n",
    "  - rvs: amostras aleatórias.\n",
    "\n",
    "Interessante notar que funções como a pdf e cdf são definidas na reta real, mesmo que a distribuição não corresponda a este suporte. Neste caso as funções vão retornar zero no caso da pdf e 0 ou 1 no caso da cdf. Por exemplo, o suporta da distribuição beta é o intervalo aberto (0,1). Assim, se a pdf fora deste intervalo será 0 e a cdf abaixo de 0 será 0 e acima de 1 será 1. \n",
    "\n",
    "Outro aspecto interessante da forma como a biblioteca `scipy.stats` implementa as distribuições é que você pode usá-las de duas formas: a primeira é a chamada forma congelada onde você inicializa a distribuição com os parâmetros de interesse e depois usa. A segunda você aplica a função diretamente passando como argumentos o ponto e os parâmetros para a avaliação da função. Vamos ver um exemplo,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08801633169107488\n",
      "0.08801633169107488\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as sp\n",
    "\n",
    "print(sp.norm.pdf(5, 3, 4)) # Avalia a distribuição Normal com mu = 3 e sigma2 = 4 no ponto 5.\n",
    "\n",
    "mydist = sp.norm(3, 4) # Modo frozen \n",
    "print(mydist.pdf(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca `scipy.stats` é muito rica em distribuições e a documentação é muito detalhada recomendo que veja o site da biblioteca [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html). Um outro aspecto útil é que todas as distribuições contínuas estão implementadas como um modelo de locação e escala. Esta é uma abordagem um pouco não usual, mas uma grande vantagem é que sabemos a parametrização de todas as distribuições contínuas previamente. A lista de distribuições é muito extensa e inclui distribuições multivariadas como a Gaussiana, Dirichlet e Wishart. \n",
    "\n",
    "Como um exemplo para explorar como usamos as distribuições da `scipy.stats` vou usar em um primeiro momento a distribuição Gaussiana porque suas propriedades são bem conhecidas. Em um segundo momento fazer usar uma distribuição não usual como a *generalized extreme value distribution*. Vamos calcular algumas quantidades da distribuição Gaussiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 25.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "my_norm = sp.norm(loc = 10, scale = 5)\n",
    "# Aspectos da distribuição\n",
    "my_norm.expect() # Esperança\n",
    "my_norm.median() # Mediana\n",
    "my_norm.moment(n = 1) # Primeiro momento (esperança)\n",
    "my_norm.moment(n = 2) # Segundo momento\n",
    "my_norm.stats() # Média e variancia\n",
    "my_norm.std() # Erro padrão\n",
    "my_norm.var() # Variance\n",
    "my_norm.entropy() # Entropia\n",
    "\n",
    "mean, var, skew, kurt = my_norm.stats(moments = 'mvsk')\n",
    "print(mean, var, skew, kurt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda não falamos sobre gráficos em python, mas eu vou inicializar uma figura, mais detalhes serão vistos nos próximos encontros. Gráfico da função densidade probabilidade.\n",
    "\n",
    "Vamos simular uma amostra aleatório da distribuição Gaussiana e fazer um histograma e sobrepor a densidade que acabamos de calcular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "x = np.linspace(my_norm.ppf(0.01), my_norm.ppf(0.99), 100)\n",
    "ax.plot(x, my_norm.pdf(x), 'r-', lw=1, alpha=0.6, label='norm pdf')\n",
    "\n",
    "amostra = my_norm.rvs(10000)\n",
    "ax.hist(amostra, density=True, histtype='stepfilled', alpha=0.2)\n",
    "ax.legend(loc='best', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro método que também está disponível para todas as distribuições implementadas na biblioteca `scipy.stats` é o método `fit`. Como o nome sugere este método ajusta a distribuição para um vetor de observações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9.677558586317708, 4.577823988903881)\n",
      "(3518998.448550458, 9.677857227098563, 4.577722231657916)\n",
      "(9.769109923281029, 2.9145346025200185)\n"
     ]
    }
   ],
   "source": [
    "amostra = my_norm.rvs(100)\n",
    "print(sp.norm.fit(amostra)) # Ajustando a própria Normal\n",
    "print(sp.t.fit(amostra)) # Ajustando a distribuição t\n",
    "print(sp.cauchy.fit(amostra)) # Cauchy ou qq outra que seja adequada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em geral as distribuições de probabilidade implementadas na biblioteca `scipy.stats` são vetorizadas. Assim, se o argumento for um objeto `ndarray` a função será aplicada em cada uma das entradas do `ndarray` e a saída também será um `ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00443185, 0.05399097, 0.24197072, 0.39894228, 0.24197072,\n",
       "       0.05399097, 0.00443185])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([-3,-2,-1,0,1,2,3])\n",
    "sp.norm.pdf(a, loc = 0, scale = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim termino esta rápida introdução de como e onde as funções de probabilidades estão implementadas em python. Na sequência vou introduzir as principais idéias de otimização de funções em python.\n",
    "\n",
    "## Otimização\n",
    "\n",
    "Otimização de funções tem um papel central em inferência estatística. Uma vez que o estimador de maxima verossimilhança é o supremo da função de log-verossimilhança encontrar este ponto é crucial para o processo de inferência. O python através do modulo `scipy.optimization` fornece vários algoritmos para numericamente encontrar o mínimo/máximo de uma função pré-especificada. Este modulo também fornece algoritmos para solução de sistemas de equações não-lineares e minimização via métodos dos mínimos quadrados. Vamos ver alguns exemplos de como usar esta poderosa biblioteca. Como exemplo vou implementar a log-verossimilhança de um modelo de regressão linear simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.22747985 2.98913084 3.96304652 3.88286941 5.25055912 5.22025798\n",
      " 7.005927   7.79190839 7.51322383 9.67606474]\n"
     ]
    }
   ],
   "source": [
    "x = np.array(range(0,10))\n",
    "par = np.array([2,0.8,0.5])\n",
    "my_norm = sp.norm(loc = 0, scale = par[2])\n",
    "e = my_norm.rvs(len(x))\n",
    "mu = par[0] + par[1]*x\n",
    "y = mu + e\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.08325619  0.77083923 -0.78114441]\n",
      "6.377595779854763\n",
      "[ 2.08325397  0.77084288 -0.78117857]\n",
      "6.377595760422819\n",
      "[ 2.08325332  0.77084298 -0.78117893]\n",
      "6.377595760417703\n",
      "[ 2.08321123  0.77084964 -0.78129439]\n",
      "6.377595905871967\n",
      "[-5.96046448e-07 -2.38418579e-06  4.76837158e-07]\n",
      "[[ 7.22133604e-02 -1.14451524e-02 -3.26751095e-04]\n",
      " [-1.14451524e-02  2.54060362e-03 -3.12294568e-05]\n",
      " [-3.26751095e-04 -3.12294568e-05  4.70887117e-02]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from math import exp, log\n",
    "\n",
    "def linreg(par, y, x):\n",
    "    mu = par[0] + par[1]*x\n",
    "    output = -sp.norm.logpdf(y, loc = mu, scale = exp(par[2])).sum()\n",
    "    #print(output)\n",
    "    return(output)\n",
    "\n",
    "# Avaliando a log-lik no ponto\n",
    "linreg(par = np.array([2.1788,0.7743, log(0.3817)]), y = y, x = x) \n",
    "\n",
    "# Valores iniciais\n",
    "par = np.array([2,0.8, log(2)])\n",
    "\n",
    "# Nelder-Mead\n",
    "res1 = minimize(linreg, par, method='nelder-mead', args = (y,x))\n",
    "print(res1.x)\n",
    "print(res1.fun)\n",
    "\n",
    "# Gradiente Conjugado\n",
    "res2 = minimize(linreg, par, method = 'CG', args = (y,x))\n",
    "print(res2.x)\n",
    "print(res2.fun)\n",
    "\n",
    "# BFGS\n",
    "res3 = minimize(linreg, par, method = 'BFGS',  args = (y,x))\n",
    "print(res3.x)\n",
    "print(res3.fun)\n",
    "\n",
    "# Powell\n",
    "res4 = minimize(linreg, par, method = 'Powell', args = (y,x))\n",
    "print(res4.x)\n",
    "print(res4.fun)\n",
    "\n",
    "# Escore\n",
    "print(res3.jac)\n",
    "\n",
    "# Temos o inverso do hessiano\n",
    "print(res3.hess_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Medida de dispersão ou variabilidade: Dispersão é a variação nos dados e mede as inconsistências no valor das variáveis nos dados. A dispersão, na verdade, fornece uma idéia sobre o spread, em vez de valores centrais.\n",
    "* Faixa: Essa é a diferença entre o máximo e o mínimo do valor.\n",
    "* Variância: é a média dos desvios ao quadrado da média (xi = pontos de dados, µ = média dos dados, N = número de pontos de dados). A dimensão da variação é o quadrado dos valores reais. A razão para usar o denominador N-1 para uma amostra em vez de N na população é devido ao grau de liberdade. 1 grau de liberdade perdido em uma amostra no momento do cálculo da variação é devido à extração da substituição da amostra:\n",
    "\n",
    "![1](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/04829f06-fff4-4694-9b3e-62508ac4a609.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample variance: 400\n",
      "Sample std.dev: 20.0\n",
      "Range: 69\n"
     ]
    }
   ],
   "source": [
    "# Deviance calculations\n",
    "\n",
    "from statistics import variance,stdev\n",
    "\n",
    "game_points = np.array([35,56,43,59,63,79,35,41,64,43,93,60,77,24,82])\n",
    "\n",
    "# Calculate Variance\n",
    "dt_var = variance(game_points)\n",
    "print (\"Sample variance:\", round(dt_var,2))\n",
    "\n",
    "# Calculate Standard Deviation\n",
    "dt_std = stdev(game_points)\n",
    "print (\"Sample std.dev:\",round(dt_std,2))\n",
    "               \n",
    "# Calculate Range\n",
    "dt_rng = np.max(game_points,axis=0) - np.min(game_points,axis=0)\n",
    "print (\"Range:\",dt_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantiles:\n",
      "20% 39.800000000000004\n",
      "80% 77.4\n",
      "100% 93.0\n",
      "Inter quartile range: 28.5\n"
     ]
    }
   ],
   "source": [
    "#Calculate percentiles\n",
    "print (\"Quantiles:\")\n",
    "\n",
    "for val in [20,80,100]:\n",
    "    dt_qntls = np.percentile(game_points,val) \n",
    "    print (str(val)+\"%\" ,dt_qntls)\n",
    "                                \n",
    "# Calculate IQR                           \n",
    "q75, q25 = np.percentile(game_points, [75 ,25])\n",
    "print (\"Inter quartile range:\",q75-q25 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: -4.38\n",
      "Critical value from t-table: -1.699\n",
      "Lower tail p-value from t-table 7.035025729010886e-05\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis testing        \n",
    "\n",
    "xbar = 990; mu0 = 1000; s = 12.5; n = 30\n",
    "\n",
    "# Test Statistic\n",
    "t_smple  = (xbar-mu0)/(s/np.sqrt(float(n)))\n",
    "print (\"Test Statistic:\",round(t_smple,2))\n",
    "\n",
    "# Critical value from t-table\n",
    "alpha = 0.05\n",
    "t_alpha = stats.t.ppf(alpha,n-1)\n",
    "print (\"Critical value from t-table:\",round(t_alpha,3))\n",
    "\n",
    "#Lower tail p-value from t-table                        \n",
    "p_val = stats.t.sf(np.abs(t_smple), n-1)\n",
    "print (\"Lower tail p-value from t-table\", p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob. to score more than 67 is  17.87 %\n"
     ]
    }
   ],
   "source": [
    "# Normal Distribution\n",
    "\n",
    "xbar = 67; mu0 = 52; s = 16.3\n",
    "\n",
    "# Calculating z-score\n",
    "z = (67-52)/16.3\n",
    "\n",
    "# Calculating probability under the curve    \n",
    "p_val = 1- stats.norm.cdf(z)\n",
    "\n",
    "print (\"Prob. to score more than 67 is \",round(p_val*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'survey.csv' does not exist: b'survey.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-124a0245f0c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msurvey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"survey.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Tabulating 2 variables with row & column variables respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'survey.csv' does not exist: b'survey.csv'"
     ]
    }
   ],
   "source": [
    "# Chi-square independence test\n",
    "import pandas as pd\n",
    "\n",
    "survey = pd.read_csv(\"survey.csv\")\n",
    "\n",
    "# Tabulating 2 variables with row & column variables respectively\n",
    "survey_tab = pd.crosstab(survey.Smoke, survey.Exer, margins = True)\n",
    "\n",
    "# Creating observed table for analysis\n",
    "observed = survey_tab.iloc[0:4,0:3] \n",
    "\n",
    "contg = stats.chi2_contingency(observed= observed)\n",
    "p_value = round(contg[1],3)\n",
    "\n",
    "print (\"P-value is: \",p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'fetilizers.csv' does not exist: b'fetilizers.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-41fb233ddfe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#ANOVA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfetilizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fetilizers.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mone_way_anova\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_oneway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetilizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fertilizer1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetilizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fertilizer2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetilizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fertilizer3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'fetilizers.csv' does not exist: b'fetilizers.csv'"
     ]
    }
   ],
   "source": [
    "#ANOVA\n",
    "\n",
    "fetilizers = pd.read_csv(\"fetilizers.csv\")\n",
    "\n",
    "one_way_anova = stats.f_oneway(fetilizers[\"fertilizer1\"], fetilizers[\"fertilizer2\"], fetilizers[\"fertilizer3\"])\n",
    "\n",
    "print (\"Statistic :\", round(one_way_anova[0],2),\", p-value :\",round(one_way_anova[1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "22\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Train & Test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "original_data = pd.read_csv(\"mtcars.csv\")\n",
    "\n",
    "train_data,test_data = train_test_split(original_data,train_size = 0.7,random_state=42)\n",
    "\n",
    "print(len(original_data))\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results\n",
      "Intercept 30.098860539622496 Coefficient [-0.06822828]\n",
      "Converged, iterations:  1140566\n",
      "Gradient Descent Results\n",
      "Intercept = [30.02495106] Coefficient = [-0.06781243]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regressio vs. Gradient Descent\n",
    "\n",
    "train_data = pd.read_csv(\"mtcars.csv\")\n",
    "                        \n",
    "X = np.array(train_data[\"hp\"])  ; y = np.array(train_data[\"mpg\"])\n",
    "X = X.reshape(32,1); y = y.reshape(32,1)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression(fit_intercept = True)\n",
    " \n",
    "model.fit(X,y)\n",
    "print (\"Linear Regression Results\")\n",
    "print (\"Intercept\",model.intercept_[0] ,\"Coefficient\",model.coef_[0])\n",
    "                   \n",
    "\n",
    "def gradient_descent(x, y,learn_rate, conv_threshold,batch_size,max_iter):\n",
    "    converged = False\n",
    "    iter = 0\n",
    "    m = batch_size \n",
    " \n",
    "    t0 = np.random.random(x.shape[1])\n",
    "    t1 = np.random.random(x.shape[1])\n",
    "\n",
    "    MSE = (sum([(t0 + t1*x[i] - y[i])**2 for i in range(m)])/ m)\n",
    "\n",
    "    while not converged:\n",
    "        grad0 = 1.0/m * sum([(t0 + t1*x[i] - y[i]) for i in range(m)])\n",
    "        grad1 = 1.0/m * sum([(t0 + t1*x[i] - y[i])*x[i] for i in range(m)])\n",
    "\n",
    "        temp0 = t0 - learn_rate * grad0\n",
    "        temp1 = t1 - learn_rate * grad1\n",
    "    \n",
    "        t0 = temp0\n",
    "        t1 = temp1\n",
    "\n",
    "        MSE_New = (sum( [ (t0 + t1*x[i] - y[i])**2 for i in range(m)] ) / m)\n",
    "\n",
    "        if abs(MSE - MSE_New ) <= conv_threshold:\n",
    "            print ('Converged, iterations: ', iter)\n",
    "            converged = True\n",
    "    \n",
    "        MSE = MSE_New\n",
    "        iter += 1\n",
    "    \n",
    "        if iter == max_iter:\n",
    "            print ('Max interactions reached')\n",
    "            converged = True\n",
    "\n",
    "    return t0,t1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Inter, Coeff = gradient_descent(x = X,y = y,learn_rate=0.00003 ,conv_threshold=1e-8, batch_size=32,max_iter=1500000)\n",
    "    print (\"Gradient Descent Results\")\n",
    "    print (('Intercept = %s Coefficient = %s') %(Inter, Coeff)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Validation Test split\n",
    "\n",
    "original_data = pd.read_csv(\"mtcars.csv\")\n",
    "\n",
    "def data_split(dat,trf = 0.5,vlf=0.25,tsf = 0.25):\n",
    "    nrows = dat.shape[0]\n",
    "    trnr = int(nrows*trf)\n",
    "    vlnr = int(nrows*vlf)\n",
    "    \n",
    "    tr_data,rmng = train_test_split(dat,train_size = trnr,random_state=42)\n",
    "    vl_data, ts_data = train_test_split(rmng,train_size = vlnr,random_state=45)\n",
    "    \n",
    "    return (tr_data,vl_data,ts_data)\n",
    "\n",
    "train_data, validation_data, test_data = data_split(original_data,trf=0.5,vlf=0.25,tsf=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best score: \n",
      " 0.970806100217865\n",
      "\n",
      " Best parameters set: \n",
      "\n",
      "\tclf__max_depth: 100\n",
      "\tclf__min_samples_leaf: 2\n",
      "\tclf__min_samples_split: 2\n",
      "\n",
      " Confusion Matrix on Test data \n",
      " [[814  19]\n",
      " [ 23 128]]\n",
      "\n",
      " Test Accuracy \n",
      " 0.9573170731707317\n",
      "\n",
      "Precision Recall f1 table \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       833\n",
      "           1       0.87      0.85      0.86       151\n",
      "\n",
      "    accuracy                           0.96       984\n",
      "   macro avg       0.92      0.91      0.92       984\n",
      "weighted avg       0.96      0.96      0.96       984\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    6.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Grid search on Decision Trees\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "input_data = pd.read_csv(\"ad.csv\",header=None)\n",
    "\n",
    "X_columns = set(input_data.columns.values)\n",
    "y = input_data[len(input_data.columns.values)-1]\n",
    "X_columns.remove(len(input_data.columns.values)-1)\n",
    "X = input_data[list(X_columns)]\n",
    "\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y,train_size = 0.7,random_state=33)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clf', DecisionTreeClassifier(criterion='entropy'))\n",
    "])\n",
    "parameters = {\n",
    "    'clf__max_depth': (50,100,150),\n",
    "    'clf__min_samples_split': (2, 3),\n",
    "    'clf__min_samples_leaf': (1, 2, 3)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print ('\\n Best score: \\n', grid_search.best_score_)\n",
    "print ('\\n Best parameters set: \\n')\n",
    "\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print ('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "print (\"\\n Confusion Matrix on Test data \\n\",confusion_matrix(y_test,y_pred))\n",
    "print (\"\\n Test Accuracy \\n\",accuracy_score(y_test,y_pred))\n",
    "print (\"\\nPrecision Recall f1 table \\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
