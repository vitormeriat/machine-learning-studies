{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelism of Statistics and Machine Learning\n",
    "\n",
    "À primeira vista, o aprendizado de máquina parece estar distante das estatísticas. No entanto, se dermos uma olhada mais profunda neles, podemos traçar paralelos entre ambos. Neste capítulo, vamos nos aprofundar nos detalhes. Foram feitas comparações entre regressão linear e regressão laço / cume, a fim de fornecer uma comparação simples entre modelagem estatística e aprendizado de máquina. Estes são modelos básicos nos dois mundos e são bons para começar.\n",
    "\n",
    "Neste capítulo, abordaremos o seguinte:\n",
    "\n",
    "* Compreensão dos parâmetros estatísticos e diagnósticos\n",
    "* Fatores compensadores em modelos de aprendizado de máquina para equiparar o diagnóstico estatístico\n",
    "* Regressão de Ridge e Lasso\n",
    "* Comparação do quadrado R (R-square) ajustado com precisão\n",
    "\n",
    "## Comparação entre modelos de regressão e aprendizado de máquina (Comparison between regression and machine learning models)\n",
    "\n",
    "Os modelos de regressão linear e aprendizado de máquina tentam resolver o mesmo problema de maneiras diferentes. No exemplo simples a seguir de uma equação de duas variáveis ajustando o melhor plano possível, os modelos de regressão tentam ajustar o melhor hiperplano possível, minimizando os erros entre o hiperplano e as observações reais. No entanto, no aprendizado de máquina, o mesmo problema foi convertido em um problema de otimização, no qual os erros são modelados no formato quadrado para minimizar erros, alterando os pesos.\n",
    "\n",
    "Na modelagem estatística, as amostras são coletadas da população e o modelo será ajustado nos dados amostrados. No entanto, no aprendizado de máquina, mesmo números pequenos, como 30 observações, seriam bons o suficiente para atualizar os pesos no final de cada iteração; em alguns casos, como aprendizado on-line, o modelo será atualizado com apenas uma observação:\n",
    "\n",
    "![1](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/190e152c-5234-4e6a-aafb-211597d96254.png)\n",
    "\n",
    "Os modelos de aprendizado de máquina podem ser efetivamente paralelizados e criados para funcionar em várias máquinas nas quais os pesos do modelo são transmitidos entre as máquinas e assim por diante. No caso de big data com Spark, essas técnicas são implementadas.\n",
    "\n",
    "Os modelos estatísticos são de natureza paramétrica, o que significa que um modelo terá parâmetros nos quais os diagnósticos são realizados para verificar a validade do modelo. Enquanto os modelos de aprendizado de máquina são não paramétricos, não possuem parâmetros ou suposições de curvas; esses modelos aprendem sozinhos com base nos dados fornecidos e apresentam funções complexas e intrincadas, em vez de ajustes de funções predefinidos.\n",
    "\n",
    "As verificações de multicolinearidade devem ser executadas na modelagem estatística. Considerando que, no espaço de aprendizado de máquina, os pesos são ajustados automaticamente para compensar o problema da multicolinearidade. Se considerarmos métodos de conjuntos baseados em árvores, como ensacamento, floresta aleatória, reforço e assim por diante, a multicolinearidade nem sequer existe, pois o modelo subjacente é uma árvore de decisão, que não apresenta um problema de multicolinearidade no primeiro Lugar, colocar.\n",
    "\n",
    "Com a evolução do big data e da computação paralela distribuída, modelos mais complexos estão produzindo resultados de ponta que eram impossíveis com a tecnologia do passado.\n",
    "\n",
    "## Fatores de compensação em modelos de aprendizado de máquina (Compensating factors in machine learning models)\n",
    "\n",
    "Os fatores de compensação nos modelos de aprendizado de máquina para equiparar o diagnóstico estatístico são explicados com o exemplo de uma viga sendo suportada por dois suportes. Se um dos suportes não existir, a viga acabará caindo ao sair do equilíbrio. Uma analogia semelhante é aplicado para comparar modelagem estatística e máquina de metodologias de aprendizagem aqui.\n",
    "\n",
    "A validação de dois pontos é realizada na metodologia de modelagem estatística em dados de treinamento usando a precisão geral do modelo e o teste de significância dos parâmetros individuais. Devido ao fato de que tanto linear ou regressão logística tem menor variância pela forma do próprio modelo, portanto, não haveria muito pouca chance de que trabalhar pior em dados invisíveis. Assim, durante a implantação, estes modelos não incorrer em muitos resultados desviado.\n",
    "\n",
    "No entanto, no espaço de aprendizado de máquina, os modelos têm um alto grau de flexibilidade que pode mudar de simples para altamente complexo. Além disso, o diagnóstico estatístico de variáveis ​​individuais não é realizado no aprendizado de máquina. Por isso, é importante para assegurar a robustez para evitar overfitting dos modelos, que assegurem a sua facilidade de utilização durante a fase de aplicação para assegurar a utilização correcta em dados invisível.\n",
    "\n",
    "Como mencionado anteriormente, na aprendizagem máquina, os dados irão ser dividida em três partes (de dados do comboio - 50 por cento, de validação de dados - 25 por cento, de teste de dados - 25 por cento), em vez de duas partes em metodologia estatística. Os modelos de aprendizado de máquina devem ser desenvolvidos com dados de treinamento e seus hiperparâmetros devem ser ajustados com base nos dados de validação para garantir a equivalência de validação de dois pontos; Dessa forma, a robustez dos modelos é garantida sem o diagnóstico realizado em um nível variável individual:\n",
    "\n",
    "![2](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/1f3fafb4-b4fc-4a4e-a35a-81816c587cc1.png)\n",
    "\n",
    "Antes de aprofundar as comparações entre os dois fluxos, começaremos a entender os fundamentos de cada modelo individualmente. Vamos começar com regressão linear! Esse modelo pode parecer trivial; no entanto, conhecer os princípios de trabalho da regressão linear criará uma base para modelos estatísticos e de aprendizado de máquina mais avançados. Abaixo estão as suposições da regressão linear.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pressupostos da regressão linear (Assumptions of linear regression)\n",
    "\n",
    "A regressão linear possui as seguintes premissas, na falta do qual o modelo de regressão linear não é verdadeiro:\n",
    "\n",
    "* A variável dependente deve ser uma combinação linear de variáveis independentes\n",
    "* Nenhuma autocorrelação em termos de erro\n",
    "* Os erros devem ter média zero e ser normalmente distribuídos\n",
    "* Nenhuma ou pouca multicolinearidade\n",
    "* Os termos do erro devem ser homoscedásticos\n",
    "\n",
    "Estes são explicados em detalhes da seguinte maneira:\n",
    "\n",
    "* A variável dependente deve ser uma combinação linear de variáveis independentes: Y deve ser uma combinação linear de variáveis X. Observe que, na equação a seguir, X2 aumentou para a potência de 2, a equação ainda mantém a suposição de uma combinação linear de variáveis:\n",
    "\n",
    "![01](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/0e340ede-9c59-4921-9b7f-0b5d72ae1288.jpg)\n",
    "\n",
    "![02](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/7b321ace-2fcb-426c-a4b2-6e87c8460d23.png)\n",
    "\n",
    "Como diagnosticar: examine parcelas residuais de variáveis residuais versus variáveis independentes. Tente também incluir termos polinomiais e ver qualquer diminuição nos valores residuais, pois os termos polinomiais podem capturar mais sinais dos dados, caso modelos lineares simples não os capturem.\n",
    "\n",
    "No gráfico da amostra anterior, inicialmente, a regressão linear foi aplicada e os erros parecem ter um padrão em vez de serem ruídos brancos puros; neste caso, está simplesmente mostrando a presença de não linearidade. Depois de aumentar a potência do valor polinomial, agora os erros simplesmente parecem ruído branco.\n",
    "\n",
    "* Sem autocorrelação em termos de erro: Presença de correlação em termos de erro penalizou a precisão do modelo.\n",
    "\n",
    "Como diagnosticar: procure o teste de Durbin-Watson. O teste de Durbin-Watson testa a hipótese nula de que os resíduos não são linearmente correlacionados automaticamente. Enquanto d pode estar entre 0 e 4, se d ≈ 2 não indica autocorrelação, 0 <d <2 implica em autocorrelação positiva e 2 <d <4 indica autocorrelação negativa.\n",
    "\n",
    "* O erro deve ter média zero e ser normalmente distribuído: os erros devem ter média zero para o modelo criar uma estimativa imparcial. A plotagem dos erros mostrará a distribuição dos erros. Considerando que, se os termos de erro não são normalmente distribuídos, isso implica que os intervalos de confiança se tornarão muito amplos ou estreitos, o que leva a dificuldades na estimativa de coeficientes com base na minimização de mínimos quadrados:\n",
    "\n",
    "![03](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/86f0b786-816d-4c71-b032-a3c9a5775e45.png)\n",
    "\n",
    "Como diagnosticar: Examine o gráfico Q-Q e também testes como os testes de Kolmogorov-Smirnov serão úteis. Observando o gráfico QQ acima, é evidente que o primeiro gráfico mostra que os erros são normalmente distribuídos, pois os resíduos não parecem se desviar muito em comparação com a linha diagonal, enquanto no gráfico à direita é claramente mostrando que os erros não são normalmente distribuídos; nesses cenários, precisamos reavaliar as variáveis realizando transformações de log e assim por diante, para fazer com que os resíduos pareçam como no gráfico à esquerda.\n",
    "\n",
    "* Nenhuma ou pouca multicolinearidade: a multicolinearidade é o caso em que variáveis independentes são correlacionadas entre si e essa situação cria modelos instáveis, inflando a magnitude dos coeficientes / estimativas. Também fica difícil determinar qual variável está contribuindo para prever a variável de resposta. O VIF é calculado para cada variável independente calculando o valor do quadrado R em relação a todas as outras variáveis independentes e tenta eliminar qual variável tem o valor mais alto do VIF, uma a uma:\n",
    "\n",
    "![04](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/873906af-6303-436c-a7df-318682cb033d.jpg)\n",
    "\n",
    "Como diagnosticar: analise os gráficos de dispersão, execute o coeficiente de correlação em todas as variáveis de dados. Calcule o fator de inflação de variação (VIF). Se VIF <= 4 não sugere multicolinearidade, em cenários bancários, as pessoas também usam VIF <= 2!\n",
    "\n",
    "* Os erros devem ser homocedásticos: os erros devem ter variação constante em relação à variável independente, o que leva a intervalos de confiança imprecticamente amplos ou estreitos para estimativas, o que prejudica o desempenho do modelo. Uma razão para não manter a homoscedasticidade é devido à presença de valores discrepantes nos dados, o que arrasta o modelo que se encaixa a eles com pesos mais altos:\n",
    "\n",
    "![05](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/f1c2f736-0b16-44a0-ad76-6a1e25442280.png)\n",
    "\n",
    "Como diagnosticar: examine o gráfico de variáveis residuais versus variáveis dependentes; se existir algum padrão de cone ou divergência, isso indica que os erros não têm variação constante, o que afeta suas previsões.\n",
    "\n",
    "### Etapas aplicadas na modelagem de regressão linear\n",
    "\n",
    "As etapas a seguir são aplicadas na modelagem de regressão linear na indústria:\n",
    "\n",
    "1. Valor em falta e tratamento externo\n",
    "2. Verificação de correlação de variáveis independentes\n",
    "3. Treinar e testar a classificação aleatória\n",
    "4. Ajustar o modelo nos dados do trem\n",
    "5. Avaliar modelo em dados de teste\n",
    "\n",
    "# Exemplo de regressão linear simples a partir dos primeiros princípios\n",
    "\n",
    "O capítulo inteiro foi apresentado com o popular conjunto de dados de qualidade do vinho, disponível abertamente no repositório de aprendizado de máquina da UCI em https://archive.ics.uci.edu/ml/datasets/Wine+Quality.\n",
    "\n",
    "A regressão linear simples é uma abordagem direta para prever a variável dependente / resposta Y, dada a variável independente / preditora X. Assume uma relação linear entre X e Y:\n",
    "\n",
    "![06](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/fcccc001-546b-4b73-9deb-f373f2a46161.png)\n",
    "\n",
    "$β0$ e $β1$ são duas constantes desconhecidas que são parâmetros de interceptação e inclinação respectivamente. Depois de determinar as constantes, podemos utilizá-las para a previsão da variável dependente:\n",
    "\n",
    "![07](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/a24e3c88-721b-4651-bab8-ce728530fba5.jpg)\n",
    "\n",
    "![08](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/0ef16a17-69ed-4a1c-aa9d-7920b781fbdc.jpg)\n",
    "\n",
    "![09](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/8ff84814-a313-46e6-a702-f01c9535ba34.jpg)\n",
    "\n",
    "![10](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/323e8b2d-acc5-404d-9d49-f05744562b3b.jpg)\n",
    "\n",
    "![11](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/f972cc37-1b5c-433d-93a4-2200d2f29bac.jpg)\n",
    "\n",
    "![12](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/3ec69204-1988-44b2-8d6d-7891a2624bdc.jpg)\n",
    "\n",
    "Resíduos são as diferenças entre o i-ésimo valor de resposta observado e o-ésimo valor de resposta que é previsto no modelo. A soma residual dos quadrados é mostrada. A abordagem de mínimos quadrados escolhe estimativas minimizando erros.\n",
    "\n",
    "Para provar estatisticamente que a regressão linear é significativa, precisamos realizar testes de hipóteses. Vamos supor que começamos com a hipótese nula de que não há relação significativa entre X e Y:\n",
    "\n",
    "![13](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/5553757d-0463-4e9a-a564-be1a5635d67b.jpg)\n",
    "\n",
    "![14](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/7ee83135-6902-4931-9157-d81ff08c4943.jpg)\n",
    "\n",
    "![15](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/e18d560e-9baf-43c9-af66-bbab63b29cc0.jpg)\n",
    "\n",
    "Como se β1 = 0, o modelo não mostra associação entre as duas variáveis (Y = β0 + ε), essas são as hipóteses nulas; para provar essa suposição certa ou errada, precisamos determinar que β1 está suficientemente longe de 0 (estatisticamente significante na distância de 0 para ser preciso), para ter certeza de que β1 é diferente de zero e tem uma relação significativa entre as duas variáveis. Agora, a pergunta é: quão longe está o suficiente de zero? Depende da distribuição de β1, que é sua média e erro padrão (semelhante ao desvio padrão). Em alguns casos, se o erro padrão for pequeno, mesmo valores relativamente pequenos podem fornecer fortes evidências de que β1 ≠ 0, portanto, há uma relação entre X e Y. Por outro lado, se SE (β1) for grande, então β1 deve ser grande em valor absoluto para rejeitarmos a hipótese nula. Geralmente, executamos o teste a seguir para verificar quantos desvios padrão β1 estão longe do valor 0:\n",
    "\n",
    "![16](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/6a3bca65-39a1-4556-9333-044d05be8cdb.jpg)\n",
    "\n",
    "![17](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/7e4b6926-fa33-497d-bbef-8821d331f184.jpg)\n",
    "\n",
    "![18](https://learning.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/c0db4d8b-e624-4c5b-a46c-05638bf8aa21.jpg)\n",
    "\n",
    "Com esse valor t, calculamos a probabilidade de observar qualquer valor igual a | t | ou maior, assumindo β1 = 0; essa probabilidade também é conhecida como valor-p. Se o valor de p <0,05, significa que β1 está significativamente longe de 0, podemos rejeitar a hipótese nula e concordar que existe uma relação forte, enquanto que se o valor de p> 0,05, aceitamos a hipótese nula e concluímos que há Não há relação significativa entre as duas variáveis.\n",
    "\n",
    "Quando tivermos os valores do coeficiente, tentaremos prever o valor dependente e verificar o valor do quadrado R; se o valor for> = 0,7, significa que o modelo é bom o suficiente para implantar em dados invisíveis, enquanto que se não for um valor tão bom (<0,6), podemos concluir que esse modelo não é bom o suficiente para implantar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
